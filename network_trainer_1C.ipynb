{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.001\n",
      "[2021-02-21 16:35:23.483280] baseline_resnet_fashionmnist Training Start\n",
      "Epoch: 1/10. Train set: Average loss: 0.0003,  Validation loss: 0.3239\n",
      "Epoch: 2/10. Train set: Average loss: 0.0001,  Validation loss: 0.2694\n",
      "Epoch: 3/10. Train set: Average loss: 0.0001,  Validation loss: 0.2421\n",
      "Epoch: 4/10. Train set: Average loss: 0.0001,  Validation loss: 0.2220\n",
      "Epoch: 5/10. Train set: Average loss: 0.0001,  Validation loss: 0.2085\n",
      "Epoch: 6/10. Train set: Average loss: 0.0001,  Validation loss: 0.2005\n",
      "Epoch: 7/10. Train set: Average loss: 0.0001,  Validation loss: 0.2021\n",
      "Epoch: 8/10. Train set: Average loss: 0.0000,  Validation loss: 0.2233\n",
      "Epoch: 9/10. Train set: Average loss: 0.0000,  Validation loss: 0.2382\n",
      "Epoch: 10/10. Train set: Average loss: 0.0000,  Validation loss: 0.2676\n",
      "[2021-02-21 16:45:56.480713] baseline_resnet_fashionmnist Training End\n",
      "\n",
      "[2021-02-21 16:45:56.740019] siam_resnet_fashionmnist Training Start\n",
      "Epoch: 1/10. Train set: Average loss: 0.0018,  Validation loss: 0.0645\n",
      "Epoch: 2/10. Train set: Average loss: 0.0000,  Validation loss: 0.0520\n",
      "Epoch: 3/10. Train set: Average loss: 0.0000,  Validation loss: 0.0447\n",
      "Epoch: 4/10. Train set: Average loss: 0.0000,  Validation loss: 0.0412\n",
      "Epoch: 5/10. Train set: Average loss: 0.0000,  Validation loss: 0.0397\n",
      "Epoch: 6/10. Train set: Average loss: 0.0000,  Validation loss: 0.0359\n",
      "Epoch: 7/10. Train set: Average loss: 0.0000,  Validation loss: 0.0344\n",
      "Epoch: 8/10. Train set: Average loss: 0.0000,  Validation loss: 0.0333\n",
      "Epoch: 9/10. Train set: Average loss: 0.0000,  Validation loss: 0.0300\n",
      "Epoch: 10/10. Train set: Average loss: 0.0000,  Validation loss: 0.0289\n",
      "[2021-02-21 17:05:47.294337] siam_resnet_fashionmnist Training End\n",
      "\n",
      "[2021-02-21 17:05:47.654049] triplet_resnet_fashionmnist Training Start\n",
      "Epoch: 1/10. Train set: Average loss: 0.0010,  Validation loss: 0.1682\n",
      "Epoch: 2/10. Train set: Average loss: 0.0000,  Validation loss: 0.1501\n",
      "Epoch: 3/10. Train set: Average loss: 0.0000,  Validation loss: 0.4851\n",
      "Epoch: 4/10. Train set: Average loss: 0.0000,  Validation loss: 0.1694\n",
      "Epoch: 5/10. Train set: Average loss: 0.0000,  Validation loss: 0.1853\n",
      "Epoch: 6/10. Train set: Average loss: 0.0000,  Validation loss: 0.1802\n",
      "Epoch: 7/10. Train set: Average loss: 0.0000,  Validation loss: 0.1996\n",
      "Epoch: 8/10. Train set: Average loss: 0.0000,  Validation loss: 0.1905\n",
      "Epoch: 9/10. Train set: Average loss: 0.0000,  Validation loss: 0.1762\n",
      "Epoch: 10/10. Train set: Average loss: 0.0000,  Validation loss: 0.1861\n",
      "[2021-02-21 17:36:07.536210] triplet_resnet_fashionmnist Training End\n",
      "\n",
      "10\n",
      "0.001\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7834891aa1d497d97d869fcef64209a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f461b26b760746408b14c6090ae3f3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267b749eb7ba4d21978f6fe81511698b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808b92f2bfdd44c3adc8d9f04e226271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "[2021-02-21 17:36:12.482481] baseline_resnet_mnist Training Start\n",
      "\n",
      "\n",
      "Epoch: 1/10. Train set: Average loss: 0.0001,  Validation loss: 0.0431\n",
      "Epoch: 2/10. Train set: Average loss: 0.0000,  Validation loss: 0.0515\n",
      "Epoch: 3/10. Train set: Average loss: 0.0000,  Validation loss: 0.0587\n",
      "Epoch: 4/10. Train set: Average loss: 0.0000,  Validation loss: 0.0266\n",
      "Epoch: 5/10. Train set: Average loss: 0.0000,  Validation loss: 0.0291\n",
      "Epoch: 6/10. Train set: Average loss: 0.0000,  Validation loss: 0.0246\n",
      "Epoch: 7/10. Train set: Average loss: 0.0000,  Validation loss: 0.0380\n",
      "Epoch: 8/10. Train set: Average loss: 0.0000,  Validation loss: 0.0395\n",
      "Epoch: 9/10. Train set: Average loss: 0.0000,  Validation loss: 0.0216\n",
      "Epoch: 10/10. Train set: Average loss: 0.0000,  Validation loss: 0.0232\n",
      "[2021-02-21 17:46:32.497064] baseline_resnet_mnist Training End\n",
      "\n",
      "[2021-02-21 17:46:32.788285] siam_resnet_mnist Training Start\n",
      "Epoch: 1/10. Train set: Average loss: 0.0020,  Validation loss: 0.0632\n",
      "Epoch: 2/10. Train set: Average loss: 0.0000,  Validation loss: 0.0346\n",
      "Epoch: 3/10. Train set: Average loss: 0.0000,  Validation loss: 0.0242\n",
      "Epoch: 4/10. Train set: Average loss: 0.0000,  Validation loss: 0.0147\n",
      "Epoch: 5/10. Train set: Average loss: 0.0000,  Validation loss: 0.0106\n",
      "Epoch: 6/10. Train set: Average loss: 0.0000,  Validation loss: 0.0081\n",
      "Epoch: 7/10. Train set: Average loss: 0.0000,  Validation loss: 0.0067\n",
      "Epoch: 8/10. Train set: Average loss: 0.0000,  Validation loss: 0.0056\n",
      "Epoch: 9/10. Train set: Average loss: 0.0000,  Validation loss: 0.0057\n",
      "Epoch: 10/10. Train set: Average loss: 0.0000,  Validation loss: 0.0052\n",
      "[2021-02-21 18:05:08.229555] siam_resnet_mnist Training End\n",
      "\n",
      "[2021-02-21 18:05:08.576626] triplet_resnet_mnist Training Start\n",
      "Epoch: 1/10. Train set: Average loss: 0.0006,  Validation loss: 0.0474\n",
      "Epoch: 2/10. Train set: Average loss: 0.0000,  Validation loss: 0.0309\n",
      "Epoch: 3/10. Train set: Average loss: 0.0000,  Validation loss: 0.0176\n",
      "Epoch: 4/10. Train set: Average loss: 0.0000,  Validation loss: 0.0250\n",
      "Epoch: 5/10. Train set: Average loss: 0.0000,  Validation loss: 0.0224\n",
      "Epoch: 6/10. Train set: Average loss: 0.0000,  Validation loss: 0.0121\n",
      "Epoch: 7/10. Train set: Average loss: 0.0000,  Validation loss: 0.0244\n",
      "Epoch: 8/10. Train set: Average loss: 0.0000,  Validation loss: 0.0178\n",
      "Epoch: 9/10. Train set: Average loss: 0.0000,  Validation loss: 0.0188\n",
      "Epoch: 10/10. Train set: Average loss: 0.0000,  Validation loss: 0.0126\n",
      "[2021-02-21 18:31:41.552939] triplet_resnet_mnist Training End\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST, MNIST\n",
    "from torchvision.datasets import SVHN, CIFAR10, CIFAR100\n",
    "from torchvision import transforms\n",
    "from utils.datasets import SiameseDataset, TripletDataset, CrossEntropyDataset\n",
    "import models.resnet, models.siamesenet, models.triplenet, models.resnet_sis\n",
    "from utils.losses import ContrastiveLoss, TripletLoss\n",
    "from utils.trainer import fit\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "torch.cuda.set_device(0)\n",
    "epoch=10\n",
    "lr=0.001\n",
    "batch_size=32\n",
    "save_type='test'\n",
    "\n",
    "input_data = ['fashionmnist','mnist']\n",
    "model_list = ['baseline','siam','triplet']\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if cuda else {}\n",
    "warnings.filterwarnings(action='ignore') # warning message off\n",
    "which_resnet = models.resnet.ResNet34\n",
    "\n",
    "class DataConfig():\n",
    "    def __init__(self, data_name):\n",
    "        if data_name == 'fashionmnist':\n",
    "            self.mean, self.std = (0.28604059698879553,), (0.35302424451492237,)\n",
    "            self.path = './data/FashionMNIST'\n",
    "            self.dataset_f = FashionMNIST\n",
    "            \n",
    "        elif data_name == 'mnist':\n",
    "            self.mean, self.std = (0.1307,), (0.3081,)\n",
    "            self.path = './data/MNIST'\n",
    "            self.dataset_f = MNIST\n",
    "            \n",
    "        elif data_name == 'svhn':\n",
    "            self.mean, self.std = [0.4380, 0.4440, 0.4730], [0.1751, 0.1771, 0.1744]\n",
    "            self.path = './data/SVHN'\n",
    "            self.dataset_f = SVHN\n",
    "            \n",
    "        elif data_name == 'cifar10':\n",
    "            self.mean, self.std = [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "            self.path = './data/CIFAR10'\n",
    "            self.dataset_f = CIFAR10\n",
    "\n",
    "        elif data_name == 'cifar100':\n",
    "            self.mean, self.std = [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "            self.path = './data/CIFAR100'\n",
    "            self.dataset_f = CIFAR100\n",
    "            \n",
    "        self.train_dataset = self.data_init(True)\n",
    "        self.test_dataset = self.data_init(False)\n",
    "            \n",
    "    def data_init(self, train_opt):\n",
    "        return self.dataset_f(self.path, \n",
    "                                        train=train_opt, \n",
    "                                        download=True, \n",
    "                                        transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(self.mean, self.std)]\n",
    "                                        ))\n",
    "\n",
    "class ModelConfig():\n",
    "    def __init__(self, model_name):\n",
    "        if model_name == 'siam':\n",
    "            self.dataset_for_model = SiameseDataset\n",
    "            self.model = models.siamesenet.SiameseNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = ContrastiveLoss(self.margin)\n",
    "            self.model_flag = True\n",
    "            \n",
    "        elif model_name == 'triplet':\n",
    "            self.dataset_for_model = TripletDataset\n",
    "            self.model = models.triplenet.TripletNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = TripletLoss(self.margin)\n",
    "            self.model_flag = True\n",
    "            \n",
    "        elif model_name == 'baseline' or model_name == 'odin':\n",
    "            self.dataset_for_model = CrossEntropyDataset\n",
    "            self.model = models.resnet_sis.ResNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = nn.CrossEntropyLoss()\n",
    "            self.model_flag = False\n",
    "\n",
    "# Excution (each data, each model)\n",
    "for data_name in input_data:\n",
    "    print(epoch)\n",
    "    print(lr)\n",
    "    # creating dataset\n",
    "    dc = DataConfig(data_name)\n",
    "    num_of_channel = len(dc.mean)\n",
    "    try:\n",
    "        num_of_classes = len(set(dc.train_dataset.labels))\n",
    "    except AttributeError:\n",
    "        try :\n",
    "            num_of_classes = len(set(dc.train_dataset.classes))\n",
    "        except AttributeError:\n",
    "            num_of_classes = len(set(dc.train_dataset.train_labels))\n",
    "    for model_name in model_list:\n",
    "        mc = ModelConfig(model_name)\n",
    "\n",
    "        # creating data loader\n",
    "        train_dataset = mc.dataset_for_model(dc.train_dataset) \n",
    "        test_dataset = mc.dataset_for_model(dc.test_dataset)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=mc.batch_size, shuffle=True, **kwargs)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=mc.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "        # training model\n",
    "        embedding_resnet = which_resnet(input_channels=num_of_channel, num_c=num_of_classes, model_flag=mc.model_flag)\n",
    "        model = mc.model(embedding_resnet)\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=mc.lr)\n",
    "        print(f\"[{datetime.now()}] {model_name}_resnet_{data_name} Training Start\")\n",
    "        model_nname = model_name + '_resnet_' + data_name\n",
    "        fit(train_loader, test_loader, model, mc.loss_f, optimizer, mc.n_epochs, cuda, mc.log_interval, save_type=save_type, model_nname=model_nname, model_flag=mc.model_flag)\n",
    "        print(f\"[{datetime.now()}] {model_name}_resnet_{data_name} Training End\", end='\\n\\n')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood_ex",
   "language": "python",
   "name": "ood_ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
