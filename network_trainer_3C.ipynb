{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.001\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[2021-02-21 16:25:52.519959] siam_resnet_cifar10 Training Start\n",
      "Epoch: 1/10. Train loss: 0.1409,  Validation loss: 0.1415\n",
      "Epoch: 2/10. Train loss: 0.0007,  Validation loss: 0.1269\n",
      "Epoch: 3/10. Train loss: 0.0006,  Validation loss: 0.1253\n",
      "Epoch: 4/10. Train loss: 0.0006,  Validation loss: 0.1243\n",
      "Epoch: 5/10. Train loss: 0.0006,  Validation loss: 0.1237\n",
      "Epoch: 6/10. Train loss: 0.0006,  Validation loss: 0.1229\n",
      "Epoch: 7/10. Train loss: 0.0006,  Validation loss: 0.1228\n",
      "Epoch: 8/10. Train loss: 0.0006,  Validation loss: 0.1226\n",
      "Epoch: 9/10. Train loss: 0.0006,  Validation loss: 0.1225\n",
      "Epoch: 10/10. Train loss: 0.0006,  Validation loss: 0.1225\n",
      "[2021-02-21 16:40:27.850204] siam_resnet_cifar10 Training End\n",
      "\n",
      "[2021-02-21 16:40:28.424667] triplet_resnet_cifar10 Training Start\n",
      "Epoch: 1/10. Train loss: 0.0260,  Validation loss: 0.9391\n",
      "Epoch: 2/10. Train loss: 0.0024,  Validation loss: 0.9056\n",
      "Epoch: 3/10. Train loss: 0.0023,  Validation loss: 0.8828\n",
      "Epoch: 4/10. Train loss: 0.0022,  Validation loss: 0.8725\n",
      "Epoch: 5/10. Train loss: 0.0022,  Validation loss: 0.8610\n",
      "Epoch: 6/10. Train loss: 0.0022,  Validation loss: 0.8637\n",
      "Epoch: 7/10. Train loss: 0.0022,  Validation loss: 0.8528\n",
      "Epoch: 8/10. Train loss: 0.0022,  Validation loss: 0.8454\n",
      "Epoch: 9/10. Train loss: 0.0021,  Validation loss: 0.8428\n",
      "Epoch: 10/10. Train loss: 0.0021,  Validation loss: 0.8410\n",
      "[2021-02-21 17:03:00.674586] triplet_resnet_cifar10 Training End\n",
      "\n",
      "10\n",
      "0.001\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[2021-02-21 17:03:02.856862] siam_resnet_cifar100 Training Start\n",
      "Epoch: 1/10. Train loss: 0.1253,  Validation loss: 0.1313\n",
      "Epoch: 2/10. Train loss: 0.0007,  Validation loss: 0.1258\n",
      "Epoch: 3/10. Train loss: 0.0006,  Validation loss: 0.1249\n",
      "Epoch: 4/10. Train loss: 0.0006,  Validation loss: 0.1244\n",
      "Epoch: 5/10. Train loss: 0.0006,  Validation loss: 0.1242\n",
      "Epoch: 6/10. Train loss: 0.0006,  Validation loss: 0.1241\n",
      "Epoch: 7/10. Train loss: 0.0006,  Validation loss: 0.1240\n",
      "Epoch: 8/10. Train loss: 0.0006,  Validation loss: 0.1239\n",
      "Epoch: 9/10. Train loss: 0.0006,  Validation loss: 0.1239\n",
      "Epoch: 10/10. Train loss: 0.0006,  Validation loss: 0.1239\n",
      "[2021-02-21 17:17:56.251444] siam_resnet_cifar100 Training End\n",
      "\n",
      "[2021-02-21 17:17:56.907688] triplet_resnet_cifar100 Training Start\n",
      "Epoch: 1/10. Train loss: 0.0234,  Validation loss: 0.9648\n",
      "Epoch: 2/10. Train loss: 0.0024,  Validation loss: 0.9293\n",
      "Epoch: 3/10. Train loss: 0.0023,  Validation loss: 0.9055\n",
      "Epoch: 4/10. Train loss: 0.0023,  Validation loss: 0.8964\n",
      "Epoch: 5/10. Train loss: 0.0023,  Validation loss: 0.8815\n",
      "Epoch: 6/10. Train loss: 0.0022,  Validation loss: 0.8751\n",
      "Epoch: 7/10. Train loss: 0.0022,  Validation loss: 0.8721\n",
      "Epoch: 8/10. Train loss: 0.0022,  Validation loss: 0.8678\n",
      "Epoch: 9/10. Train loss: 0.0022,  Validation loss: 0.8633\n",
      "Epoch: 10/10. Train loss: 0.0022,  Validation loss: 0.8617\n",
      "[2021-02-21 17:41:17.800949] triplet_resnet_cifar100 Training End\n",
      "\n",
      "10\n",
      "0.001\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/SVHN\\train_32x32.mat\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d19e85224a046ba85d131854cd7816c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using downloaded and verified file: ./data/SVHN\\test_32x32.mat\n",
      "[2021-02-21 17:41:35.484012] siam_resnet_svhn Training Start\n",
      "Epoch: 1/10. Train loss: 0.0338,  Validation loss: 24.9264\n",
      "Epoch: 2/10. Train loss: 0.0016,  Validation loss: 0.2995\n",
      "Epoch: 3/10. Train loss: 0.0005,  Validation loss: 4.4504\n",
      "Epoch: 4/10. Train loss: 0.0005,  Validation loss: 3.2789\n",
      "Epoch: 5/10. Train loss: 0.0005,  Validation loss: 4.7312\n",
      "Epoch: 6/10. Train loss: 0.0005,  Validation loss: 2.5667\n",
      "Epoch: 7/10. Train loss: 0.0005,  Validation loss: 1.2172\n",
      "Epoch: 8/10. Train loss: 0.0005,  Validation loss: 0.4355\n",
      "Epoch: 9/10. Train loss: 0.0005,  Validation loss: 0.3472\n",
      "Epoch: 10/10. Train loss: 0.0005,  Validation loss: 0.4000\n",
      "[2021-02-21 18:00:10.153345] siam_resnet_svhn Training End\n",
      "\n",
      "[2021-02-21 18:00:10.917301] triplet_resnet_svhn Training Start\n",
      "Epoch: 1/10. Train loss: 0.0117,  Validation loss: 0.9903\n",
      "Epoch: 2/10. Train loss: 0.0017,  Validation loss: 0.9368\n",
      "Epoch: 3/10. Train loss: 0.0016,  Validation loss: 0.8987\n",
      "Epoch: 4/10. Train loss: 0.0015,  Validation loss: 0.8420\n",
      "Epoch: 5/10. Train loss: 0.0014,  Validation loss: 0.8137\n",
      "Epoch: 6/10. Train loss: 0.0013,  Validation loss: 0.8050\n",
      "Epoch: 7/10. Train loss: 0.0008,  Validation loss: 0.8359\n",
      "Epoch: 8/10. Train loss: 0.0007,  Validation loss: 0.8177\n",
      "Epoch: 9/10. Train loss: 0.0005,  Validation loss: 0.8005\n",
      "Epoch: 10/10. Train loss: 0.0004,  Validation loss: 0.7987\n",
      "[2021-02-21 18:25:07.372958] triplet_resnet_svhn Training End\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST, MNIST\n",
    "from torchvision.datasets import SVHN, CIFAR10, CIFAR100\n",
    "from torchvision import transforms\n",
    "from utils.datasets import SiameseDataset, TripletDataset, CrossEntropyDataset\n",
    "import models.resnet, models.siamesenet, models.triplenet, models.resnet_sis\n",
    "from utils.losses import ContrastiveLoss, TripletLoss\n",
    "from utils.trainer_sch import fit\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "torch.cuda.set_device(1)\n",
    "epoch=10\n",
    "lr=0.001\n",
    "batch_size=256\n",
    "save_type=\"test\"\n",
    "\n",
    "input_data = ['cifar10','cifar100','svhn']\n",
    "model_list = ['siam', 'triplet']\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if cuda else {}\n",
    "warnings.filterwarnings(action='ignore') # warning message off\n",
    "which_resnet = models.resnet.ResNet34\n",
    "\n",
    "class DataConfig():\n",
    "    def __init__(self, data_name):\n",
    "        if data_name == 'fashionmnist':\n",
    "            self.mean, self.std = (0.28604059698879553,), (0.35302424451492237,)\n",
    "            self.path = './data/FashionMNIST'\n",
    "            self.dataset_f = FashionMNIST\n",
    "            \n",
    "        elif data_name == 'mnist':\n",
    "            self.mean, self.std = (0.1307,), (0.3081,)\n",
    "            self.path = './data/MNIST'\n",
    "            self.dataset_f = MNIST\n",
    "            \n",
    "        elif data_name == 'svhn':\n",
    "            self.mean, self.std = [0.4380, 0.4440, 0.4730], [0.1751, 0.1771, 0.1744]\n",
    "            self.path = './data/SVHN'\n",
    "            self.dataset_f = SVHN\n",
    "            \n",
    "        elif data_name == 'cifar10':\n",
    "            self.mean, self.std = [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "            self.path = './data/CIFAR10'\n",
    "            self.dataset_f = CIFAR10\n",
    "\n",
    "        elif data_name == 'cifar100':\n",
    "            self.mean, self.std = [0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]\n",
    "            self.path = './data/CIFAR100'\n",
    "            self.dataset_f = CIFAR100\n",
    "            \n",
    "        if data_name == 'svhn':\n",
    "            self.train_dataset = self.data_init('train')\n",
    "            self.test_dataset = self.data_init('test')\n",
    "        else:\n",
    "            self.train_dataset = self.data_init(True)\n",
    "            self.test_dataset = self.data_init(False)\n",
    "            \n",
    "    def data_init(self, train_opt):\n",
    "        try:\n",
    "            return self.dataset_f(self.path, \n",
    "                                            train=train_opt, \n",
    "                                            download=True, \n",
    "                                            transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                                                 transforms.Normalize(self.mean, self.std)]\n",
    "                                            ))\n",
    "        except:\n",
    "            return self.dataset_f(self.path, \n",
    "                                            split=train_opt, \n",
    "                                            download=True, \n",
    "                                            transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                                                 transforms.Normalize(self.mean, self.std)]\n",
    "                                            ))\n",
    "\n",
    "class ModelConfig():\n",
    "    def __init__(self, model_name):\n",
    "        if model_name == 'siam':\n",
    "            self.dataset_for_model = SiameseDataset\n",
    "            self.model = models.siamesenet.SiameseNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = ContrastiveLoss(self.margin)\n",
    "            self.model_flag = True\n",
    "            \n",
    "        elif model_name == 'triplet':\n",
    "            self.dataset_for_model = TripletDataset\n",
    "            self.model = models.triplenet.TripletNet\n",
    "            self.batch_size = 128\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = TripletLoss(self.margin)\n",
    "            self.model_flag = True\n",
    "            \n",
    "        elif model_name == 'baseline' or model_name == 'odin':\n",
    "            self.dataset_for_model = CrossEntropyDataset\n",
    "            self.model = models.resnet_sis.ResNet\n",
    "            self.batch_size = batch_size\n",
    "            self.margin = 1.\n",
    "            self.lr = lr\n",
    "            self.n_epochs = epoch\n",
    "            self.log_interval = 50\n",
    "            self.loss_f = nn.CrossEntropyLoss()\n",
    "            self.model_flag = False\n",
    "            \n",
    "# Excution (each data, each model)\n",
    "for data_name in input_data:\n",
    "    print(epoch)\n",
    "    print(lr)\n",
    "    # creating dataset\n",
    "    dc = DataConfig(data_name)\n",
    "    num_of_channel = len(dc.mean)\n",
    "    try:\n",
    "        num_of_classes = len(set(dc.train_dataset.labels))\n",
    "    except AttributeError:\n",
    "        try :\n",
    "            num_of_classes = len(set(dc.train_dataset.classes))\n",
    "        except AttributeError:\n",
    "            num_of_classes = len(set(dc.train_dataset.train_labels))\n",
    "    for model_name in model_list:\n",
    "        mc = ModelConfig(model_name)\n",
    "\n",
    "        # creating data loader\n",
    "        train_dataset = mc.dataset_for_model(dc.train_dataset) \n",
    "        test_dataset = mc.dataset_for_model(dc.test_dataset)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=mc.batch_size, shuffle=True, **kwargs)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=mc.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "        # training model\n",
    "        pre_resnet = models.resnet.ResNet34(num_c=100)\n",
    "        embedding_resnet=pre_resnet#.embedding_net\n",
    "        model = mc.model(embedding_resnet)\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=mc.lr, weight_decay=0.0001)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epoch*len(train_loader), eta_min=0)\n",
    "        print(f\"[{datetime.now()}] {model_name}_resnet_{data_name} Training Start\")\n",
    "        model_nname = model_name + '_resnet_' + data_name\n",
    "        fit(train_loader, test_loader, model, mc.loss_f, optimizer, scheduler, mc.n_epochs, cuda, mc.log_interval, model_nname=model_nname, save_type=save_type, model_flag=mc.model_flag)\n",
    "        print(f\"[{datetime.now()}] {model_name}_resnet_{data_name} Training End\", end='\\n\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood_ex",
   "language": "python",
   "name": "ood_ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
